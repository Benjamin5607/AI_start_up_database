import os
import feedparser
import json
import time
import datetime
from groq import Groq
from notion_client import Client
from bs4 import BeautifulSoup

# --- í™˜ê²½ë³€ìˆ˜ ---
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
NOTION_API_KEY = os.environ.get("NOTION_API_KEY")
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")

groq_client = Groq(api_key=GROQ_API_KEY)
notion_client = Client(auth=NOTION_API_KEY)

# --- [í•µì‹¬] í˜„ì¬ ì‚´ì•„ìˆëŠ” ëª¨ë¸ ì¤‘ ì§± ì„¼ ë†ˆ ë°ë ¤ì˜¤ê¸° ---
def get_alive_model():
    try:
        models = groq_client.models.list()
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™•ë³´
        available_models = [m.id for m in models.data]
        
        # 1ìˆœìœ„: 70b (ë˜‘ë˜‘í•œ ë†ˆ)ì´ë©´ì„œ ìµœì‹ (3.x)ì¸ ë†ˆ ì°¾ê¸°
        for m in available_models:
            if "70b" in m and "llama-3" in m:
                print(f"ğŸ¤– ëª¨ë¸ ìë™ ì„ íƒë¨: {m}")
                return m
        
        # 2ìˆœìœ„: 70b ì•„ë¬´ê±°ë‚˜
        for m in available_models:
            if "70b" in m:
                print(f"ğŸ¤– ëª¨ë¸ ìë™ ì„ íƒë¨(ëŒ€íƒ€): {m}")
                return m
                
        # 3ìˆœìœ„: ì—ë¼ ëª¨ë¥´ê² ë‹¤ ì•„ë¬´ê±°ë‚˜ (ë³´í†µ 8b)
        fallback = available_models[0]
        print(f"ğŸ¤– ëª¨ë¸ ìë™ ì„ íƒë¨(ìµœí›„ì˜ ìˆ˜ë‹¨): {fallback}")
        return fallback
        
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        return "llama-3.3-70b-versatile" # ìµœí›„ì˜ ë³´ë£¨

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ í™•ì •
CURRENT_MODEL = get_alive_model()

# --- [ìˆ˜ì§‘] TechCrunch RSS ---
def get_techcrunch_rss():
    rss_url = "https://techcrunch.com/category/artificial-intelligence/feed/"
    feed = feedparser.parse(rss_url)
    
    articles = []
    print(f"ğŸ” RSS ê²€ìƒ‰ ê²°ê³¼: {len(feed.entries)}ê°œì˜ ê¸°ì‚¬ ë°œê²¬")
    
    for entry in feed.entries[:3]: 
        title = entry.title
        link = entry.link
        summary_text = BeautifulSoup(entry.description, "html.parser").get_text()
        articles.append({'title': title, 'link': link, 'content': summary_text})
    
    return articles

# --- [ê°€ê³µ] Groq ---
def analyze_with_groq(title, content):
    prompt = f"""
    Analyze this startup news for a VC investor.
    Title: {title}
    Content Snippet: {content}
    
    Output strictly JSON (Korean):
    {{
        "company_name": "íšŒì‚¬ëª…(ì˜ë¬¸)",
        "funding": "íˆ¬ìê¸ˆì•¡(ì˜ˆ: $10M) ì—†ìœ¼ë©´ 'ì •ë³´ì—†ìŒ'",
        "summary": "1ì¤„ ìš”ì•½(ì¡´ëŒ“ë§)",
        "bm": "ìˆ˜ìµ ëª¨ë¸",
        "score": 1 to 10
    }}
    """
    try:
        completion = groq_client.chat.completions.create(
            model=CURRENT_MODEL, # ğŸ‘ˆ ì•„ê¹Œ ì„ ë°œí•œ ê·¸ ë†ˆ ë“¤ì–´ê°
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return json.loads(completion.choices[0].message.content)
    except Exception as e:
        print(f"âŒ Groq Error ({CURRENT_MODEL}): {e}")
        return None

# --- [ì ì¬] ë…¸ì…˜ ---
def upload_to_notion(data, link):
    try:
        notion_client.pages.create(
            parent={"database_id": NOTION_DATABASE_ID},
            properties={
                "íšŒì‚¬ëª…": {"title": [{"text": {"content": data.get("company_name", "Unknown")}}]},
                "íˆ¬ìê·œëª¨": {"rich_text": [{"text": {"content": data.get("funding", "-")}}]},
                "í•œì¤„ìš”ì•½": {"rich_text": [{"text": {"content": data.get("summary", "-")}}]},
                "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": {"rich_text": [{"text": {"content": data.get("bm", "-")}}]},
                "ë§¤ë ¥ë„": {"number": int(data.get("score", 0))},
                "ë‚ ì§œ": {"date": {"start": datetime.date.today().isoformat()}},
                "ì›ë¬¸ë§í¬": {"url": link}
            }
        )
        print(f"âœ… ë…¸ì…˜ ì—…ë¡œë“œ ì„±ê³µ: {data.get('company_name')}")
    except Exception as e:
        print(f"âŒ ë…¸ì…˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

# --- ì‹¤í–‰ ---
if __name__ == "__main__":
    print(f"ğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ê°€ë™ (Selected Model: {CURRENT_MODEL})...")
    news_list = get_techcrunch_rss()
    
    if not news_list:
        print("âš ï¸ ë‰´ìŠ¤ë¥¼ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    for news in news_list:
        print(f"Processing: {news['title']}...")
        ai_data = analyze_with_groq(news['title'], news['content'])
        if ai_data:
            upload_to_notion(ai_data, news['link'])
        time.sleep(2)
