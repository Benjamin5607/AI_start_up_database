import os
import requests
import json
import time
import datetime
import jwt
import xml.etree.ElementTree as ET
from groq import Groq
from notion_client import Client

# --- Environments ---
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
NOTION_API_KEY = os.environ.get("NOTION_API_KEY")
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")

# Ghost Credentials
GHOST_API_KEY = os.environ.get("GHOST_API_KEY")
GHOST_API_URL = os.environ.get("GHOST_API_URL")

client = Groq(api_key=GROQ_API_KEY)
notion = Client(auth=NOTION_API_KEY)

def get_best_model():
    try:
        models = client.models.list()
        ids = [m.id for m in models.data]
        return "llama-3.3-70b-versatile" if "llama-3.3-70b-versatile" in ids else ids[0]
    except: return "llama-3.3-70b-versatile"

CURRENT_MODEL = get_best_model()

# --- [Check] ë…¸ì…˜ ë‚´ ì¤‘ë³µ ë°ì´í„° í™•ì¸ ---
def is_already_processed(link):
    try:
        # ë…¸ì…˜ì˜ 'ì›ë¬¸ë§í¬' ì†ì„±ì—ì„œ í•´ë‹¹ URLì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ ì¿¼ë¦¬
        query = notion.databases.query(
            database_id=NOTION_DATABASE_ID,
            filter={
                "property": "ì›ë¬¸ë§í¬",
                "url": {"equals": link}
            }
        )
        return len(query.get("results", [])) > 0
    except Exception as e:
        print(f"âš ï¸ ì¤‘ë³µ ì²´í¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

# --- [Collection] Google News RSS (ë‹¤ì–‘í™” ë° ìµœì‹  í•„í„° ì ìš©) ---
def fetch_massive_infra_alpha():
    data = []
    # ì¤‘ë³µì„ í”¼í•˜ê¸° ìœ„í•´ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ë„“íˆê³  íŠ¹ì • ê¸°ì—… í¸ì¤‘ì„ ì¤„ì„
    queries = [
        "AI+datacenter+liquid+cooling+market+startups",
        "TSMC+advanced+packaging+supply+chain+news",
        "HBM4+HBM3E+semiconductor+manufacturing+partners",
        "AI+infrastructure+energy+power+grid+innovations",
        "Silicon+photonics+optical+interconnect+startups",
        "Edge+AI+hardware+chipset+breakthroughs",
        "NVIDIA+Blackwell+supply+chain+challenges" # ì—”ë¹„ë””ì•„ëŠ” í•˜ë‚˜ë¡œ ì¶•ì†Œ
    ]
    headers = {"User-Agent": "Mozilla/5.0"}
    
    for q in queries:
        try:
            # &tbs=qdr:d ì˜µì…˜ìœ¼ë¡œ ìµœê·¼ 24ì‹œê°„ ì´ë‚´ì˜ ë‰´ìŠ¤ë§Œ í•„í„°ë§
            url = f"https://news.google.com/rss/search?q={q}&hl=en-US&gl=US&ceid=US:en&tbs=qdr:d"
            response = requests.get(url, headers=headers, timeout=15)
            root = ET.fromstring(response.content)
            
            for item in root.findall('.//item')[:10]:
                link = item.find('link').text
                # [ì¤‘ìš”] ë…¸ì…˜ì— ì´ë¯¸ ìˆëŠ” ë°ì´í„°ë¼ë©´ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì§€ ì•ŠìŒ
                if not is_already_processed(link):
                    data.append({'title': item.find('title').text, 'link': link})
                else:
                    print(f"â­ï¸ Skipping duplicate: {item.find('title').text[:30]}...")
        except: pass
        time.sleep(1)
    return data

# --- [Analysis] VC Analysis ---
def analyze_high_quality(title, link):
    prompt = f"""
    Analyze this for a Tier-1 VC Investment Report.
    Title: {title}
    Link: {link}
    STRICT RULES:
    1. Respond in JSON. 2. LANGUAGE: ENGLISH.
    3. Identify 2 relevant category tags (e.g., "Semiconductor", "Data Center", "Cooling", "Power", "Networking").
    JSON Structure:
    {{
        "entity_name": "Company name",
        "role": "Role in AI Ecosystem",
        "tech_analysis": "Technical moat analysis",
        "partners": "Major partners",
        "impact_score": 1-10,
        "investment_insight": "VC strategic insight",
        "tags": ["Tag1", "Tag2"]
    }}
    """
    try:
        completion = client.chat.completions.create(
            model=CURRENT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        return json.loads(completion.choices[0].message.content)
    except: return None

# --- [Load] Notion ---
def push_to_notion(data, link):
    try:
        notion_tags = [{"name": tag} for tag in data.get('tags', ["AI Infra"])]
        notion.pages.create(
            parent={"database_id": NOTION_DATABASE_ID},
            properties={
                "íšŒì‚¬ëª…": {"title": [{"text": {"content": data['entity_name']}}]},
                "Category": {"multi_select": notion_tags},
                "íˆ¬ìê·œëª¨": {"rich_text": [{"text": {"content": data['role']}}]},
                "í•œì¤„ìš”ì•½": {"rich_text": [{"text": {"content": data['tech_analysis']}}]},
                "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": {"rich_text": [{"text": {"content": f"Partners: {data['partners']} | Insight: {data['investment_insight']}"}}]},
                "ë§¤ë ¥ë„": {"number": int(data.get('impact_score', 0))},
                "ë‚ ì§œ": {"date": {"start": datetime.date.today().isoformat()}},
                "ì›ë¬¸ë§í¬": {"url": link}
            }
        )
        return True
    except: return False

# --- [Post] Ghost Admin API ---
def post_to_ghost(title, html_content):
    try:
        key_id, secret = GHOST_API_KEY.split(':')
        iat = int(time.time())
        header = {'alg': 'HS256', 'typ': 'JWT', 'kid': key_id}
        payload = {'iat': iat, 'exp': iat + 5 * 60, 'aud': '/admin/'}
        token = jwt.encode(payload, bytes.fromhex(secret), algorithm='HS256', headers=header)
        
        url = f"{GHOST_API_URL.rstrip('/')}/ghost/api/admin/posts/?source=html"
        headers = {'Authorization': f'Ghost {token}'}
        body = {"posts": [{"title": title, "html": html_content, "status": "published"}]}
        
        res = requests.post(url, json=body, headers=headers)
        if res.status_code == 201:
            print(f"âœ… Ghost Post Published: {title}")
        else:
            print(f"âŒ Ghost Error: {res.json()}")
    except Exception as e:
        print(f"âŒ Ghost Integration Error: {e}")

# --- [Image Finder] íšŒì‚¬ ë¡œê³  ì´ë¯¸ì§€ ìë™ ê²€ìƒ‰ ---
def find_company_logo(company_name):
    try:
        # DDG APIë¥¼ í†µí•´ ì´ë¯¸ì§€ URL í™•ë³´ ì‹œë„
        search_url = f"https://api.duckduckgo.com/?q={company_name} logo icon&format=json"
        res = requests.get(search_url, timeout=5).json()
        if res.get('Image'):
            return res['Image']
    except: pass
    return "https://via.placeholder.com/200?text=Company+Logo"

# --- [Report] ìƒ/ì¤‘/í•˜ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„± ---
def create_comparison_report(results):
    if not results: return
    
    all_tags = []
    for r in results: all_tags.extend(r.get('tags', []))
    target_cat = max(set(all_tags), key=all_tags.count) if all_tags else "AI Infrastructure"
    
    cat_items = [r for r in results if target_cat in r.get('tags', [])]
    cat_items.sort(key=lambda x: x['impact_score'], reverse=True)
    
    if len(cat_items) < 3: 
        print(f"âš ï¸ {target_cat} ì¹´í…Œê³ ë¦¬ì— ë¹„êµí•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (í˜„ì¬ {len(cat_items)}ê°œ).")
        return
        
    high, mid, low = cat_items[0], cat_items[len(cat_items)//2], cat_items[-1]
    
    high_logo = find_company_logo(high['entity_name'])
    mid_logo = find_company_logo(mid['entity_name'])
    low_logo = find_company_logo(low['entity_name'])

    prompt = f"""
    Create a highly detailed, professional VC investment blog post in HTML format.
    The post must be at least A4 page equivalent in length (approx. 800-1000 words).
    Theme: Deep Dive into {target_cat} Market Trends and Investment Opportunities.
    
    Structure:
    1. <h2>Executive Summary: The Global Status of {target_cat}</h2>
    2. <h2>The Comparison: Market Leader vs Challenger vs Emerging</h2>
       - For each company, include: Entity Name, Role, Moat Analysis, and Investment Insight.
       - Use the provided image URLs in <img> tags.
    3. <h2>Macro Outlook: Industry Tailwinds and Challenges</h2>
    4. <h2>VC Conclusion: Strategic Takeaway</h2>
    
    Data:
    - Leader (Score {high['impact_score']}): {high['entity_name']} (Logo: {high_logo})
    - Challenger (Score {mid['impact_score']}): {mid['entity_name']} (Logo: {mid_logo})
    - Risky (Score {low['impact_score']}): {low['entity_name']} (Logo: {low_logo})
    
    STRICT RULES:
    - Pure HTML output only.
    - Elaborate deeply on business insights, industrial context, and global trends.
    """
    try:
        response = client.chat.completions.create(
            model=CURRENT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2500 
        )
        report_html = response.choices[0].message.content
        report_title = f"[Analysis] {target_cat} Deep-Dive: From Infrastructure to Alpha ({datetime.date.today()})"
        post_to_ghost(report_title, report_html)
    except Exception as e:
        print(f"âŒ Report Generation Failed: {e}")

# --- Main ---
if __name__ == "__main__":
    print(f"ğŸš€ AI Alpha Scraper v3 (Deduplication Enabled) Initiated.")
    raw_list = fetch_massive_infra_alpha()
    print(f"ğŸ“¦ Found {len(raw_list)} new unique candidates to analyze.")
    
    report_pool = []
    unique_links = set()
    success_count = 0
    
    for item in raw_list:
        if success_count >= 50: break
        if item['link'] in unique_links: continue # ì¤‘ë³µ ìˆ˜ì§‘ ë°©ì§€
        
        print(f"[{success_count+1}/50] Analyzing: {item['title'][:50]}...")
        res = analyze_high_quality(item['title'], item['link'])
        
        if res and int(res.get('impact_score', 0)) >= 6:
            if push_to_notion(res, item['link']):
                report_pool.append(res)
                success_count += 1
                unique_links.add(item['link'])
                print(f"   âœ… Saved to Notion. ğŸ’¤ Sleeping 8s...")
                time.sleep(8)
        else:
            time.sleep(1)

    if report_pool:
        print(f"ğŸ“ Creating In-depth Comparison Report (Target Pool: {len(report_pool)} items)...")
        create_comparison_report(report_pool)

    print(f"ğŸ Mission Complete. {success_count} new leads added.")
