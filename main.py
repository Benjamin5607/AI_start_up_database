import os
import requests
import json
import time
import datetime
import xml.etree.ElementTree as ET # RSS íŒŒì‹±ìš©
from groq import Groq
from notion_client import Client

# --- Environments ---
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
NOTION_API_KEY = os.environ.get("NOTION_API_KEY")
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")

client = Groq(api_key=GROQ_API_KEY)
notion = Client(auth=NOTION_API_KEY)

def get_best_model():
    try:
        models = client.models.list()
        ids = [m.id for m in models.data]
        return "llama-3.3-70b-versatile" if "llama-3.3-70b-versatile" in ids else ids[0]
    except: return "llama-3.3-70b-versatile"

CURRENT_MODEL = get_best_model()

# --- [Collection] Google News RSS (Massive & Reliable) ---
def fetch_massive_infra_alpha():
    data = []
    # Google News RSS queries for AI Infrastructure
    queries = [
        "NVIDIA+Blackwell+supply+chain",
        "AI+Data+Center+cooling+solutions",
        "TSMC+CoWoS+partners",
        "Semiconductor+startup+funding",
        "AI+infrastructure+power+grid"
    ]
    
    for q in queries:
        try:
            # Google News RSSëŠ” ì°¨ë‹¨ì´ ê±°ì˜ ì—†ê³  ë°ì´í„°ê°€ í’ë¶€í•¨
            url = f"https://news.google.com/rss/search?q={q}&hl=en-US&gl=US&ceid=US:en"
            response = requests.get(url, timeout=10)
            root = ET.fromstring(response.content)
            
            for item in root.findall('.//item')[:15]: # ì¿¼ë¦¬ë‹¹ 15ê°œì”© í™•ë³´
                title = item.find('title').text
                link = item.find('link').text
                data.append({'title': title, 'link': link})
        except Exception as e:
            print(f"âš ï¸ Query '{q}' failed: {e}")
        time.sleep(1)
    
    return data

# --- [Analysis & Load í†µí•©] ---
def process_and_push(item, success_count):
    # AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ (Category íƒœê·¸ í¬í•¨)
    prompt = f"""
    Analyze this for a Tier-1 VC Investment Report.
    Title: {item['title']}
    Link: {item['link']}

    STRICT RULES:
    1. Respond in JSON. 2. LANGUAGE: ENGLISH.
    3. Identify 2-3 relevant category tags (e.g., "Semiconductor", "Data Center", "Cooling", "Power", "Networking", "AI Startup").

    JSON Structure:
    {{
        "entity_name": "Company/Project Name",
        "role": "Role in AI Ecosystem",
        "tech_analysis": "Technical moat analysis",
        "partners": "Major partners",
        "impact_score": 1-10,
        "investment_insight": "VC perspective insight",
        "tags": ["Tag1", "Tag2"]
    }}
    """
    try:
        completion = client.chat.completions.create(
            model=CURRENT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        res = json.loads(completion.choices[0].message.content)
        
        # ì ìˆ˜ í•„í„°ë§ (6ì  ì´ìƒë§Œ)
        if int(res.get('impact_score', 0)) >= 6:
            notion_tags = [{"name": tag} for tag in res.get('tags', ["AI Infra"])]
            notion.pages.create(
                parent={"database_id": NOTION_DATABASE_ID},
                properties={
                    "íšŒì‚¬ëª…": {"title": [{"text": {"content": res['entity_name']}}]},
                    "Category": {"multi_select": notion_tags},
                    "íˆ¬ìê·œëª¨": {"rich_text": [{"text": {"content": res['role']}}]},
                    "í•œì¤„ìš”ì•½": {"rich_text": [{"text": {"content": res['tech_analysis']}}]},
                    "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": {"rich_text": [{"text": {"content": f"Partners: {res['partners']} | Insight: {res['investment_insight']}"}}]},
                    "ë§¤ë ¥ë„": {"number": int(res['impact_score'])},
                    "ë‚ ì§œ": {"date": {"start": datetime.date.today().isoformat()}},
                    "ì›ë¬¸ë§í¬": {"url": item['link']}
                }
            )
            print(f"   âœ… [{success_count+1}/50] Added: {res['entity_name']} (Score: {res['impact_score']})")
            return True
    except Exception as e:
        print(f"   âŒ Error processing {item['title'][:30]}: {e}")
    return False

if __name__ == "__main__":
    print(f"ğŸš€ Global AI Infra Scraper Initiated. (Model: {CURRENT_MODEL})")
    raw_candidates = fetch_massive_infra_alpha()
    print(f"ğŸ“¦ Total {len(raw_candidates)} candidates found. Processing...")

    unique_links = set()
    success_count = 0
    
    for item in raw_candidates:
        if success_count >= 50: break
        if not item.get('link') or item['link'] in unique_links: continue
        
        print(f"Analyzing candidate: {item['title'][:50]}...")
        if process_and_push(item, success_count):
            success_count += 1
            unique_links.add(item['link'])
            print(f"   ğŸ’¤ Sleeping 8 seconds to stay safe...")
            time.sleep(8)
        else:
            time.sleep(1) # Skip ì‹œì—ë„ ì§§ì€ íœ´ì‹

    print(f"ğŸ Finished. Total {success_count} leads added to Notion.")
