import os
import requests
import json
import time
import datetime
from bs4 import BeautifulSoup
from groq import Groq
from notion_client import Client

# --- 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (GitHub Secretsì—ì„œ ê°€ì ¸ì˜´) ---
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")
NOTION_API_KEY = os.environ.get("NOTION_API_KEY")
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
groq_client = Groq(api_key=GROQ_API_KEY)
notion_client = Client(auth=NOTION_API_KEY)

# --- 2. [ìˆ˜ì§‘] TechCrunch AI ë‰´ìŠ¤ í¬ë¡¤ë§ ---
def get_techcrunch_news():
    url = "https://techcrunch.com/category/artificial-intelligence/"
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36"
    }
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    articles = []
    # TechCrunch êµ¬ì¡° (ë³€ê²½ ê°€ëŠ¥ì„± ìˆìŒ, loop-card í´ë˜ìŠ¤ ê¸°ì¤€)
    # ìµœì‹  5ê°œë§Œ ê°€ì ¸ì˜¤ê¸°
    for item in soup.select('.loop-card__title-link')[:5]: 
        title = item.get_text().strip()
        link = item['href']
        articles.append({'title': title, 'link': link})
    
    return articles

# --- 3. [ê°€ê³µ] Groq (Llama3-70b) ìš”ì•½ ---
def analyze_with_groq(title, link):
    prompt = f"""
    You are a professional VC analyst. Analyze the startup news below.
    Article: {title} ({link})
    
    Output purely in JSON format (Korean):
    {{
        "company_name": "íšŒì‚¬ëª…(ì˜ë¬¸)",
        "funding": "íˆ¬ìê¸ˆì•¡(ì˜ˆ: $10M) í˜¹ì€ 'ì •ë³´ì—†ìŒ'",
        "summary": "ì´ˆë“±í•™ìƒë„ ì´í•´í•˜ëŠ” 1ì¤„ ìš”ì•½(ì¡´ëŒ“ë§)",
        "bm": "ìˆ˜ìµ ëª¨ë¸(ëˆ ë²„ëŠ” ë²•) ê°„ëµ ì„¤ëª…",
        "score": "íˆ¬ì ë§¤ë ¥ë„(1~10ì )"
    }}
    """
    
    try:
        completion = groq_client.chat.completions.create(
            model="llama3-70b-8192", # Groqì—ì„œ ê°€ì¥ ë˜‘ë˜‘í•œ ëª¨ë¸
            messages=[
                {"role": "system", "content": "You are a JSON generator."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"} # JSON ëª¨ë“œ ê°•ì œ
        )
        return json.loads(completion.choices[0].message.content)
    except Exception as e:
        print(f"Groq Error: {e}")
        return None

# --- 4. [ì ì¬] ë…¸ì…˜ ì—…ë¡œë“œ ---
def upload_to_notion(data, link):
    notion_client.pages.create(
        parent={"database_id": NOTION_DATABASE_ID},
        properties={
            "íšŒì‚¬ëª…": {"title": [{"text": {"content": data.get("company_name", "Unknown")}}]},
            "íˆ¬ìê·œëª¨": {"rich_text": [{"text": {"content": data.get("funding", "-")}}]},
            "í•œì¤„ìš”ì•½": {"rich_text": [{"text": {"content": data.get("summary", "-")}}]},
            "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": {"rich_text": [{"text": {"content": data.get("bm", "-")}}]},
            "ë§¤ë ¥ë„": {"number": int(data.get("score", 0))},
            "ë‚ ì§œ": {"date": {"start": datetime.date.today().isoformat()}},
            "ì›ë¬¸ë§í¬": {"url": link}
        }
    )

# --- ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    print("ğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    news_list = get_techcrunch_news()
    
    for news in news_list:
        print(f"Processing: {news['title']}...")
        
        # Groq ë¶„ì„
        ai_data = analyze_with_groq(news['title'], news['link'])
        
        if ai_data:
            # ë…¸ì…˜ ì—…ë¡œë“œ
            upload_to_notion(ai_data, news['link'])
            print("âœ… ì—…ë¡œë“œ ì™„ë£Œ")
        else:
            print("âŒ ë¶„ì„ ì‹¤íŒ¨")
            
        # Groq ë¬´ë£Œ í‹°ì–´ ë°°ë ¤ (ë„ˆë¬´ ë¹ ë¥´ë©´ ë§‰í ìˆ˜ ìˆìŒ)
        time.sleep(2) 
        
    print("ğŸ‰ ì˜¤ëŠ˜ ì—…ë¬´ ë! (ì´ì œ ë…¸ì…˜ í™•ì¸í•˜ì„¸ìš”)")
